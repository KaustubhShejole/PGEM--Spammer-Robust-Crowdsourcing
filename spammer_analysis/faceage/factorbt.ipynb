{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0818267b",
   "metadata": {},
   "source": [
    "***\n",
    "10 random seeds: range(20, 30)\n",
    "for data creation for each type of spammer\n",
    "\n",
    "invoke factor bt\n",
    "\n",
    "get factor bt accuracy (+- std dev), wacc and tau\n",
    "\n",
    "save in results/spammer_type/factor_bt.csv\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1e751",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8113cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 21 09:31:19 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              47W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   51C    P0              81W / 300W |    529MiB / 81920MiB |     19%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   72C    P0             318W / 300W |  49971MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   46C    P0              75W / 300W |   5990MiB / 81920MiB |     98%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73b4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f6620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PyTorch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebe90e",
   "metadata": {},
   "source": [
    "### Importing FactorBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e34d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(1, \"../../\")\n",
    "\n",
    "from spammer_types import *\n",
    "from util import *\n",
    "import opt_fair\n",
    "from crowdkit.aggregation import NoisyBradleyTerry\n",
    "from distribution_utils import crowd_bt_dist, logistic_preference_dist, comparisons_to_df, safe_kendalltau, to_numpy\n",
    "from metrics import compute_acc, compute_weighted_acc\n",
    "from pgem import EMWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bc5a8",
   "metadata": {},
   "source": [
    "## Passage dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b959cb1",
   "metadata": {},
   "source": [
    "### Get the original df of passage dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ed9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../../real_data/faceage/data/crowd_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90af9cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>label</th>\n",
       "      <th>performer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   left  \\\n",
       "0     https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6306  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6176  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6175  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6174  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "\n",
       "                                                  right  \\\n",
       "0     https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6306  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6176  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6175  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "6174  https://tlk.s3.yandex.net/annotation_tasks/IMD...   \n",
       "\n",
       "                                                  label  performer  \n",
       "0     https://tlk.s3.yandex.net/annotation_tasks/IMD...          0  \n",
       "6306  https://tlk.s3.yandex.net/annotation_tasks/IMD...          0  \n",
       "6176  https://tlk.s3.yandex.net/annotation_tasks/IMD...          0  \n",
       "6175  https://tlk.s3.yandex.net/annotation_tasks/IMD...          0  \n",
       "6174  https://tlk.s3.yandex.net/annotation_tasks/IMD...          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(df_path)\n",
    "def sort_df(df, column_name):\n",
    "        # Sort by a specific column (replace 'column_name' with your column)\n",
    "        df_sorted = df.sort_values(by=column_name, ascending=True)  # or ascending=False\n",
    "\n",
    "        return df_sorted\n",
    "df = sort_df(df, 'performer')\n",
    "df[['left', 'right', 'label', 'performer']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1d9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_path = \"../../real_data/faceage/data/gt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e57894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>https://tlk.s3.yandex.net/annotation_tasks/IMD...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  label  score\n",
       "4897  https://tlk.s3.yandex.net/annotation_tasks/IMD...     42\n",
       "4901  https://tlk.s3.yandex.net/annotation_tasks/IMD...     42\n",
       "5425  https://tlk.s3.yandex.net/annotation_tasks/IMD...     46\n",
       "2054  https://tlk.s3.yandex.net/annotation_tasks/IMD...     23\n",
       "7920  https://tlk.s3.yandex.net/annotation_tasks/IMD...     62"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gt_df = pd.read_csv(gt_df_path)\n",
    "def sort_df(df, column_name):\n",
    "        # Sort by a specific column (replace 'column_name' with your column)\n",
    "        df_sorted = df.sort_values(by=column_name, ascending=True)  # or ascending=False\n",
    "\n",
    "        return df_sorted\n",
    "gt_df = sort_df(gt_df, 'label')\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c85ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = [10, 20, 40, 60, 80]\n",
    "# percents = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a2fc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>score</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm1442940_rm3965098752_1996-10-3_2006.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm4832920_rm1781768448_2003-8-28_2013.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0652089_rm860657920_1992-3-10_2002.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0004917_rm1493730304_1969-5-12_1979.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm1113550_rm1332711936_1996-4-14_2006.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9145</th>\n",
       "      <td>475367_1941-08-03_2011.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>304085_1919-07-07_1989.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>nm0001627_rm4164078592_1927-2-20_1997.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>nm0000024_rm1715129344_1904-4-14_1974.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>nm0000323_rm3114703104_1933-3-14_2003.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      full_path  score  gender\n",
       "0     nm1442940_rm3965098752_1996-10-3_2006.jpg     10     0.0\n",
       "1     nm4832920_rm1781768448_2003-8-28_2013.jpg     10     0.0\n",
       "2      nm0652089_rm860657920_1992-3-10_2002.jpg     10     0.0\n",
       "3     nm0004917_rm1493730304_1969-5-12_1979.jpg     10     0.0\n",
       "4     nm1113550_rm1332711936_1996-4-14_2006.jpg     10     0.0\n",
       "...                                         ...    ...     ...\n",
       "9145                 475367_1941-08-03_2011.jpg     70     1.0\n",
       "9146                 304085_1919-07-07_1989.jpg     70     1.0\n",
       "9147  nm0001627_rm4164078592_1927-2-20_1997.jpg     70     1.0\n",
       "9148  nm0000024_rm1715129344_1904-4-14_1974.jpg     70     1.0\n",
       "9149  nm0000323_rm3114703104_1933-3-14_2003.jpg     70     1.0\n",
       "\n",
       "[9150 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../../real_data/faceage/data/FaceAgeDF.pickle\", \"rb\") as handle:\n",
    "    df_passage = pickle.load(handle)\n",
    "df_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e001603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9150\n"
     ]
    }
   ],
   "source": [
    "size = len(df_passage)\n",
    "print(size)\n",
    "classes = [0] * size\n",
    "# for faceage it would be classes = df_passage['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2670497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df(df, column_name):\n",
    "    # Sort by a specific column (replace 'column_name' with your column)\n",
    "    df_sorted = df.sort_values(by=column_name, ascending=True)  # or ascending=False\n",
    "\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b7de5",
   "metadata": {},
   "source": [
    "### Addition of Random Guessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c28c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spammer_type = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce42a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"results/{spammer_type}/factorbt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0c07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"results/{spammer_type}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "808d4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# -------------------------\n",
    "# Write CSV header\n",
    "# -------------------------\n",
    "header = [\n",
    "    \"percent\",\n",
    "    \"FactorBT_acc_mean\", \"FactorBT_acc_std\",\n",
    "    \"FactorBT_wacc_mean\", \"FactorBT_wacc_std\",\n",
    "    \"FactorBT_tau_mean\", \"FactorBT_tau_std\"\n",
    "]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a3af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "max_iter_pgem = 100\n",
    "import pandas as pd\n",
    "\n",
    "for percent in percents:\n",
    "    # initialize metrics\n",
    "    FactorBT_accs, FactorBT_waccs, FactorBT_taus = [], [], []\n",
    "    \n",
    "    for sd in range(20, 30):\n",
    "        try:\n",
    "            # get df\n",
    "            random_df, spammer_ids = add_random_spammer(df, percent, seed=sd)\n",
    "            K = len(list(random_df[\"performer\"].unique()))\n",
    "            print(K)\n",
    "            random_df.rename(columns={\"performer\": \"worker\"}, inplace=True)\n",
    "        \n",
    "            agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(random_df)\n",
    "            agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "            factorbt_scores = list(agg_noisybt_df['score'])\n",
    "            annot_bt_np = to_numpy(factorbt_scores)\n",
    "            \n",
    "            if np.isnan(annot_bt_np).any():\n",
    "                    continue\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "            if FactorBT_tau < 0:\n",
    "                annot_bt_np = -annot_bt_np\n",
    "            FactorBT_acc = compute_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_wacc = compute_weighted_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"FactorBT failed due to {e}\")\n",
    "            continue\n",
    "        FactorBT_accs.append(FactorBT_acc)\n",
    "        FactorBT_waccs.append(FactorBT_wacc)\n",
    "        FactorBT_taus.append(FactorBT_tau)\n",
    "\n",
    "    row = [\n",
    "        percent,\n",
    "        np.mean(FactorBT_accs), np.std(FactorBT_accs),\n",
    "        np.mean(FactorBT_waccs), np.std(FactorBT_waccs),\n",
    "        np.mean(FactorBT_taus), np.std(FactorBT_taus)\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    print(\n",
    "    f\"FactorBT | \"\n",
    "    f\"Percent: {percent} |\"\n",
    "    f\"Acc: {np.mean(FactorBT_accs):.4f} ± {np.std(FactorBT_accs):.4f} | \"\n",
    "    f\"WAcc: {np.mean(FactorBT_waccs):.4f} ± {np.std(FactorBT_waccs):.4f} | \"\n",
    "    f\"Tau: {np.mean(FactorBT_taus):.4f} ± {np.std(FactorBT_taus):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf261110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7b18b5",
   "metadata": {},
   "source": [
    "### Addition of Anti-Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spammer_type = \"anti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"results/{spammer_type}/factorbt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56324fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"results/{spammer_type}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# -------------------------\n",
    "# Write CSV header\n",
    "# -------------------------\n",
    "header = [\n",
    "    \"percent\",\n",
    "    \"FactorBT_acc_mean\", \"FactorBT_acc_std\",\n",
    "    \"FactorBT_wacc_mean\", \"FactorBT_wacc_std\",\n",
    "    \"FactorBT_tau_mean\", \"FactorBT_tau_std\"\n",
    "]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_pgem = 100\n",
    "import pandas as pd\n",
    "\n",
    "for percent in percents:\n",
    "    # initialize metrics\n",
    "    FactorBT_accs, FactorBT_waccs, FactorBT_taus = [], [], []\n",
    "    \n",
    "    for sd in range(20, 30):\n",
    "        try:\n",
    "            # get df\n",
    "            random_df, spammer_ids = add_anti_personas(df, percent, seed=sd)\n",
    "            K = len(list(random_df[\"performer\"].unique()))\n",
    "            print(K)\n",
    "            random_df.rename(columns={\"performer\": \"worker\"}, inplace=True)\n",
    "        \n",
    "            agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(random_df)\n",
    "            agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "            factorbt_scores = list(agg_noisybt_df['score'])\n",
    "            annot_bt_np = to_numpy(factorbt_scores)\n",
    "            \n",
    "            if np.isnan(annot_bt_np).any():\n",
    "                    continue\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "            if FactorBT_tau < 0:\n",
    "                annot_bt_np = -annot_bt_np\n",
    "            FactorBT_acc = compute_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_wacc = compute_weighted_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"FactorBT failed due to {e}\")\n",
    "            continue\n",
    "        FactorBT_accs.append(FactorBT_acc)\n",
    "        FactorBT_waccs.append(FactorBT_wacc)\n",
    "        FactorBT_taus.append(FactorBT_tau)\n",
    "\n",
    "    row = [\n",
    "        percent,\n",
    "        np.mean(FactorBT_accs), np.std(FactorBT_accs),\n",
    "        np.mean(FactorBT_waccs), np.std(FactorBT_waccs),\n",
    "        np.mean(FactorBT_taus), np.std(FactorBT_taus)\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    print(\n",
    "    f\"FactorBT | \"\n",
    "    f\"Percent: {percent} |\"\n",
    "    f\"Acc: {np.mean(FactorBT_accs):.4f} ± {np.std(FactorBT_accs):.4f} | \"\n",
    "    f\"WAcc: {np.mean(FactorBT_waccs):.4f} ± {np.std(FactorBT_waccs):.4f} | \"\n",
    "    f\"Tau: {np.mean(FactorBT_taus):.4f} ± {np.std(FactorBT_taus):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374465e5",
   "metadata": {},
   "source": [
    "### Addition of Left Position-Biased Spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "spammer_type = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"results/{spammer_type}/factorbt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"results/{spammer_type}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# -------------------------\n",
    "# Write CSV header\n",
    "# -------------------------\n",
    "header = [\n",
    "    \"percent\",\n",
    "    \"FactorBT_acc_mean\", \"FactorBT_acc_std\",\n",
    "    \"FactorBT_wacc_mean\", \"FactorBT_wacc_std\",\n",
    "    \"FactorBT_tau_mean\", \"FactorBT_tau_std\"\n",
    "]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_pgem = 100\n",
    "import pandas as pd\n",
    "\n",
    "for percent in percents:\n",
    "    # initialize metrics\n",
    "    FactorBT_accs, FactorBT_waccs, FactorBT_taus = [], [], []\n",
    "    \n",
    "    for sd in range(20, 30):\n",
    "        try:\n",
    "            # get df\n",
    "            random_df, spammer_ids = add_position_biased_spammers(df, percent,position_bias=\"left\", seed=sd)\n",
    "            K = len(list(random_df[\"performer\"].unique()))\n",
    "            print(K)\n",
    "            random_df.rename(columns={\"performer\": \"worker\"}, inplace=True)\n",
    "        \n",
    "            agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(random_df)\n",
    "            agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "            factorbt_scores = list(agg_noisybt_df['score'])\n",
    "            annot_bt_np = to_numpy(factorbt_scores)\n",
    "            \n",
    "            if np.isnan(annot_bt_np).any():\n",
    "                    continue\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "            if FactorBT_tau < 0:\n",
    "                annot_bt_np = -annot_bt_np\n",
    "            FactorBT_acc = compute_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_wacc = compute_weighted_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"FactorBT failed due to {e}\")\n",
    "            continue\n",
    "        FactorBT_accs.append(FactorBT_acc)\n",
    "        FactorBT_waccs.append(FactorBT_wacc)\n",
    "        FactorBT_taus.append(FactorBT_tau)\n",
    "\n",
    "    row = [\n",
    "        percent,\n",
    "        np.mean(FactorBT_accs), np.std(FactorBT_accs),\n",
    "        np.mean(FactorBT_waccs), np.std(FactorBT_waccs),\n",
    "        np.mean(FactorBT_taus), np.std(FactorBT_taus)\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    print(\n",
    "    f\"FactorBT | \"\n",
    "    f\"Percent: {percent} |\"\n",
    "    f\"Acc: {np.mean(FactorBT_accs):.4f} ± {np.std(FactorBT_accs):.4f} | \"\n",
    "    f\"WAcc: {np.mean(FactorBT_waccs):.4f} ± {np.std(FactorBT_waccs):.4f} | \"\n",
    "    f\"Tau: {np.mean(FactorBT_taus):.4f} ± {np.std(FactorBT_taus):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530b3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a900492d",
   "metadata": {},
   "source": [
    "### Addition of Right Position Biased Spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spammer_type = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"results/{spammer_type}/factorbt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"results/{spammer_type}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e93f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# -------------------------\n",
    "# Write CSV header\n",
    "# -------------------------\n",
    "header = [\n",
    "    \"percent\",\n",
    "    \"FactorBT_acc_mean\", \"FactorBT_acc_std\",\n",
    "    \"FactorBT_wacc_mean\", \"FactorBT_wacc_std\",\n",
    "    \"FactorBT_tau_mean\", \"FactorBT_tau_std\"\n",
    "]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_pgem = 100\n",
    "import pandas as pd\n",
    "\n",
    "for percent in percents:\n",
    "    # initialize metrics\n",
    "    FactorBT_accs, FactorBT_waccs, FactorBT_taus = [], [], []\n",
    "    \n",
    "    for sd in range(20, 30):\n",
    "        try:\n",
    "            # get df\n",
    "            random_df, spammer_ids = add_position_biased_spammers(df, percent,position_bias=\"right\", seed=sd)\n",
    "            K = len(list(random_df[\"performer\"].unique()))\n",
    "            print(K)\n",
    "            random_df.rename(columns={\"performer\": \"worker\"}, inplace=True)\n",
    "        \n",
    "            agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(random_df)\n",
    "            agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "            factorbt_scores = list(agg_noisybt_df['score'])\n",
    "            annot_bt_np = to_numpy(factorbt_scores)\n",
    "            \n",
    "            if np.isnan(annot_bt_np).any():\n",
    "                    continue\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "            if FactorBT_tau < 0:\n",
    "                annot_bt_np = -annot_bt_np\n",
    "            FactorBT_acc = compute_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_wacc = compute_weighted_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"FactorBT failed due to {e}\")\n",
    "            continue\n",
    "        FactorBT_accs.append(FactorBT_acc)\n",
    "        FactorBT_waccs.append(FactorBT_wacc)\n",
    "        FactorBT_taus.append(FactorBT_tau)\n",
    "\n",
    "    row = [\n",
    "        percent,\n",
    "        np.mean(FactorBT_accs), np.std(FactorBT_accs),\n",
    "        np.mean(FactorBT_waccs), np.std(FactorBT_waccs),\n",
    "        np.mean(FactorBT_taus), np.std(FactorBT_taus)\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    print(\n",
    "    f\"FactorBT | \"\n",
    "    f\"Percent: {percent} |\"\n",
    "    f\"Acc: {np.mean(FactorBT_accs):.4f} ± {np.std(FactorBT_accs):.4f} | \"\n",
    "    f\"WAcc: {np.mean(FactorBT_waccs):.4f} ± {np.std(FactorBT_waccs):.4f} | \"\n",
    "    f\"Tau: {np.mean(FactorBT_taus):.4f} ± {np.std(FactorBT_taus):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905b909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf356f3",
   "metadata": {},
   "source": [
    "### Addition of Equal Proportion of all four kind of spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ac1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spammer_type = \"equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a17dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"results/{spammer_type}/factorbt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"results/{spammer_type}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# -------------------------\n",
    "# Write CSV header\n",
    "# -------------------------\n",
    "header = [\n",
    "    \"percent\",\n",
    "    \"FactorBT_acc_mean\", \"FactorBT_acc_std\",\n",
    "    \"FactorBT_wacc_mean\", \"FactorBT_wacc_std\",\n",
    "    \"FactorBT_tau_mean\", \"FactorBT_tau_std\"\n",
    "]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_pgem = 100\n",
    "import pandas as pd\n",
    "\n",
    "for percent in percents:\n",
    "    # initialize metrics\n",
    "    FactorBT_accs, FactorBT_waccs, FactorBT_taus = [], [], []\n",
    "    \n",
    "    for sd in range(20, 30):\n",
    "        try:\n",
    "            # get df\n",
    "            random_df, spammer_ids = add_equal_proportion_of_all_spammers(df, percent, seed=sd)\n",
    "            K = len(list(random_df[\"performer\"].unique()))\n",
    "            print(K)\n",
    "            random_df.rename(columns={\"performer\": \"worker\"}, inplace=True)\n",
    "        \n",
    "            agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(random_df)\n",
    "            agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "            factorbt_scores = list(agg_noisybt_df['score'])\n",
    "            annot_bt_np = to_numpy(factorbt_scores)\n",
    "            \n",
    "            if np.isnan(annot_bt_np).any():\n",
    "                    continue\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "            if FactorBT_tau < 0:\n",
    "                annot_bt_np = -annot_bt_np\n",
    "            FactorBT_acc = compute_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_wacc = compute_weighted_acc(gt_df, annot_bt_np, device)\n",
    "            FactorBT_tau = safe_kendalltau(annot_bt_np, gt_df['score'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"FactorBT failed due to {e}\")\n",
    "            continue\n",
    "        FactorBT_accs.append(FactorBT_acc)\n",
    "        FactorBT_waccs.append(FactorBT_wacc)\n",
    "        FactorBT_taus.append(FactorBT_tau)\n",
    "\n",
    "    row = [\n",
    "        percent,\n",
    "        np.mean(FactorBT_accs), np.std(FactorBT_accs),\n",
    "        np.mean(FactorBT_waccs), np.std(FactorBT_waccs),\n",
    "        np.mean(FactorBT_taus), np.std(FactorBT_taus)\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    print(\n",
    "    f\"FactorBT | \"\n",
    "    f\"Percent: {percent} |\"\n",
    "    f\"Acc: {np.mean(FactorBT_accs):.4f} ± {np.std(FactorBT_accs):.4f} | \"\n",
    "    f\"WAcc: {np.mean(FactorBT_waccs):.4f} ± {np.std(FactorBT_waccs):.4f} | \"\n",
    "    f\"Tau: {np.mean(FactorBT_taus):.4f} ± {np.std(FactorBT_taus):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb7fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
