{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e282d19",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85068cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import choix\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib import colors\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from metrics import compute_acc, compute_weighted_acc\n",
    "from opt_fair import *\n",
    "from distribution_utils import safe_kendalltau, to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff18766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 19 12:12:12 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   77C    P0             294W / 300W |  60740MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              68W / 300W |    583MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   58C    P0              76W / 300W |  60194MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             214W / 300W |  30300MiB / 81920MiB |     81%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce218d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca395bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PyTorch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48371bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/PassagePC.pickle\", 'rb') as handle:\n",
    "    PC_faceage = pickle.load(handle)    \n",
    "with open(\"data/PassageDF.pickle\", 'rb') as handle:\n",
    "    df_faceage = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea527e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a star. Our planet, Earth, orbits, or circles,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam, We did not have plastic toys. I played w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who said the little owl. Who wants to hunt wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dead leaf. This is a mole. Moles burrow underg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ereaddatagradepsenvironcomp.html Environment r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>work over the summer on any changes they wish ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>between January and December plunged the Unite...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>into a newly opened bank account. I was amazed...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>occurring phenomenon, manmade by products are ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>question requires students to use context clue...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  score\n",
       "0    a star. Our planet, Earth, orbits, or circles,...      1\n",
       "1    Adam, We did not have plastic toys. I played w...      1\n",
       "2    Who said the little owl. Who wants to hunt wit...      1\n",
       "3    dead leaf. This is a mole. Moles burrow underg...      1\n",
       "4    ereaddatagradepsenvironcomp.html Environment r...      1\n",
       "..                                                 ...    ...\n",
       "467  work over the summer on any changes they wish ...     12\n",
       "468  between January and December plunged the Unite...     12\n",
       "469  into a newly opened bank account. I was amazed...     12\n",
       "470  occurring phenomenon, manmade by products are ...     12\n",
       "471  question requires students to use context clue...     12\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faceage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a0e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n"
     ]
    }
   ],
   "source": [
    "import opt_fair\n",
    "all_pc_faceage  = opt_fair._pc_without_reviewers(PC_faceage)\n",
    "\n",
    "size = len(df_faceage)\n",
    "print(size)\n",
    "classes = [0]*size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4148d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11763\n"
     ]
    }
   ],
   "source": [
    "print(len(all_pc_faceage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877f787",
   "metadata": {},
   "source": [
    "### Gradient EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9175d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from grad_em import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202b2d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:05<00:00, 168.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:05<00:00, 166.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:07<00:00, 136.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:07<00:00, 134.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:05<00:00, 192.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:04<00:00, 208.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:05<00:00, 189.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:07<00:00, 135.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:06<00:00, 161.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1000/1000 [00:05<00:00, 172.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max_epochs without full convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Grad_accs, Grad_waccs, Grad_taus = [], [], []\n",
    "lr = 0.01\n",
    "for sd in range(10):\n",
    "    grad_em = GradientEMWrapper(PC_faceage, lr, sd, device)\n",
    "    r_est, beta_est = grad_em.run_algorithm()\n",
    "    r_est_np = to_numpy(r_est)\n",
    "    gt_scores = to_numpy(df_faceage['score'].tolist())\n",
    "    current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "    if current_tau < 0:\n",
    "        r_est_np = -r_est_np\n",
    "    grad_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "    grad_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "    grad_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "    \n",
    "    Grad_accs.append(grad_acc)    \n",
    "    Grad_waccs.append(grad_wacc)    \n",
    "    Grad_taus.append(grad_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f195f840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradEM -- Accuracy: 0.6985240876674652 ± 0.0008998396815844701, Weighted Accuracy: 0.7583310902118683 ± 0.0009670574004366093, Kendall's Tau: 0.3748170366665421 ± 0.0016989014194708297\n"
     ]
    }
   ],
   "source": [
    "print(f\"GradEM -- Accuracy: {np.mean(Grad_accs)} ± {np.std(Grad_accs)}, Weighted Accuracy: {np.mean(Grad_waccs)} ± {np.std(Grad_waccs)}, Kendall's Tau: {np.mean(Grad_taus)} ± {np.std(Grad_taus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8e23a",
   "metadata": {},
   "source": [
    "### PG EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a7044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pgem import EMWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6843935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 2/100 [00:00<00:26,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.454190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████▉                         | 34/100 [00:05<00:10,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 34, Log-likelihood change = -4.768372e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 2/100 [00:00<00:14,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.453150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 20/100 [00:03<00:12,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 20, Log-likelihood change = -1.490116e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [00:00<00:15,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.455186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▌                                 | 12/100 [00:01<00:14,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 12, Log-likelihood change = 0.000000e+00\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 2/100 [00:00<00:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.454898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████▊                          | 31/100 [00:04<00:09,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 31, Log-likelihood change = 9.834766e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [00:00<00:10,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.455264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▌                                   | 9/100 [00:01<00:12,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 9, Log-likelihood change = -2.980232e-08\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [00:00<00:11,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.454877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 10/100 [00:01<00:12,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 10, Log-likelihood change = 2.384186e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [00:00<00:11,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.455003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▎                                | 14/100 [00:01<00:10,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 14, Log-likelihood change = -6.556511e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 2/100 [00:00<00:17,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.585252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▏                                 | 11/100 [00:01<00:11,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 11, Log-likelihood change = -1.490116e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [00:00<00:11,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.453979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▉                            | 26/100 [00:03<00:09,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 26, Log-likelihood change = -4.172325e-07\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 2/100 [00:00<00:12,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000: Log-likelihood = -0.454710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▍                               | 17/100 [00:02<00:10,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 17, Log-likelihood change = -8.642673e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "\n",
    "PGEM_accs, PGEM_waccs, PGEM_taus = [], [], []\n",
    "\n",
    "for sd in range(10):\n",
    "    pg = EMWrapper(PC_faceage, max_iter, device, sd)\n",
    "    r_est, beta_est, ll = pg.run_algorithm()\n",
    "    if np.isnan(r_est).any() or np.isnan(beta_est).any() or np.isnan(ll):\n",
    "        print(\"Skipping nan\")\n",
    "        continue\n",
    "    r_est_np = to_numpy(r_est)\n",
    "    gt_scores = to_numpy(df_faceage['score'].tolist())\n",
    "    current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "    if current_tau < 0:\n",
    "        r_est_np = -r_est_np\n",
    "    pgem_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "    pgem_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "    pgem_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "    \n",
    "    PGEM_accs.append(pgem_acc)    \n",
    "    PGEM_waccs.append(pgem_wacc)    \n",
    "    PGEM_taus.append(pgem_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3848169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6941558718681335,\n",
       " 0.6948524713516235,\n",
       " 0.6951048374176025,\n",
       " 0.6942265629768372,\n",
       " 0.6951553225517273,\n",
       " 0.6953774094581604,\n",
       " 0.6948827505111694,\n",
       " 0.6935905814170837,\n",
       " 0.6943678855895996,\n",
       " 0.694751501083374]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGEM_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbff555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGEM -- Accuracy: 0.6946465194225311 ± 0.0005217393074741697, Weighted Accuracy: 0.755181896686554 ± 0.0006608944057229961, Kendall's Tau: 0.3674961233890967 ± 0.0009850565225552452\n"
     ]
    }
   ],
   "source": [
    "print(f\"PGEM -- Accuracy: {np.mean(PGEM_accs)} ± {np.std(PGEM_accs)}, Weighted Accuracy: {np.mean(PGEM_waccs)} ± {np.std(PGEM_waccs)}, Kendall's Tau: {np.mean(PGEM_taus)} ± {np.std(PGEM_taus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02388db8",
   "metadata": {},
   "source": [
    "### BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ded2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45 s, sys: 2min 16s, total: 3min 1s\n",
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bt_scores = choix.opt_pairwise(size, all_pc_faceage, alpha=0, method='Newton-CG', initial_params=None, max_iter=None, tol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cc3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est_np = to_numpy(bt_scores)\n",
    "current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "if current_tau < 0:\n",
    "    r_est_np = -r_est_np\n",
    "bt_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "bt_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "bt_tau = safe_kendalltau(r_est_np, gt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebc99132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple BT -- Accuracy: 0.6804668307304382, Weighted Accuracy: 0.74333256483078, Kendall's Tau: 0.3408721163582005 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Simple BT -- Accuracy: {bt_acc}, Weighted Accuracy: {bt_wacc}, Kendall's Tau: {bt_tau} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430a38e",
   "metadata": {},
   "source": [
    "### BARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d728c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [0]\n",
    "FaceAge = opt_fair.BARP(data = PC_faceage, penalty = 0, classes = classes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93de0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_labels = pd.read_csv('data/passage_cleaned.csv')\n",
    "num_reviewers =  crowd_labels['performer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1e0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 100/100 [01:37<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 36.3 s, total: 1min 38s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "annot_bt_temp, annot_bias =  opt_fair._alternate_optim_torch(size, num_reviewers, FaceAge, iters = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b052799",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est_np = to_numpy(annot_bt_temp)\n",
    "current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "if current_tau < 0:\n",
    "    r_est_np = -r_est_np\n",
    "barp_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "barp_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "barp_tau = safe_kendalltau(r_est_np, gt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b3b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARP -- Accuracy: 0.6920762658119202, Weighted Accuracy: 0.7587689757347107, Kendall's Tau: 0.36267695314604337 \n"
     ]
    }
   ],
   "source": [
    "print(f\"BARP -- Accuracy: {barp_acc}, Weighted Accuracy: {barp_wacc}, Kendall's Tau: {barp_tau} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72950e9",
   "metadata": {},
   "source": [
    "### RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b654f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.1 ms, sys: 35.2 ms, total: 80.3 ms\n",
      "Wall time: 78.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rc_obj = RankCentrality(device)\n",
    "A = rc_obj.matrix_of_comparisons(size, all_pc_faceage)\n",
    "# print(\"A matrix done\")\n",
    "P = rc_obj.trans_prob(A)\n",
    "# print(\"P matrix done\")\n",
    "pi = rc_obj.stationary_dist(P)\n",
    "rank_centrality_scores = torch.log(pi).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f566bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est_np = to_numpy(rank_centrality_scores)\n",
    "current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "if current_tau < 0:\n",
    "    r_est_np = -r_est_np\n",
    "rc_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "rc_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "rc_tau = safe_kendalltau(r_est_np, gt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "495a5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RC -- Accuracy: 0.6521800756454468, Weighted Accuracy: 0.71303790807724, Kendall's Tau: 0.2891796316210329 \n"
     ]
    }
   ],
   "source": [
    "print(f\"RC -- Accuracy: {rc_acc}, Weighted Accuracy: {rc_wacc}, Kendall's Tau: {rc_tau} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094082b",
   "metadata": {},
   "source": [
    "### CrowdBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35110a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_labels = pd.read_csv('data/passage_cleaned.csv')\n",
    "num_reviewers =  crowd_labels['performer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "559f5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "gt_scores = to_numpy(df_faceage['score'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7fc992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 100/100 [00:00<00:00, 172.99it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 234.26it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 264.95it/s, loss=5.06e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 221.34it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 162.98it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 131.20it/s, loss=5.06e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 125.61it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 168.03it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 167.49it/s, loss=5.07e+3]\n",
      "100%|██████████████████████| 100/100 [00:00<00:00, 173.20it/s, loss=5.07e+3]\n"
     ]
    }
   ],
   "source": [
    "CrowdBT_accs, CrowdBT_waccs, CrowdBT_taus = [], [], []\n",
    "K = num_reviewers\n",
    "gt_df = df_faceage\n",
    "for seed in range(10):\n",
    "    try:\n",
    "        crowdbt_test = opt_fair.CrowdBT_3_0(data=PC_faceage, penalty=0, device=device, random_seed=seed)\n",
    "        crowdbt_scores, _ = crowdbt_test.alternate_optim(size, K)\n",
    "        r_est_np = to_numpy(crowdbt_scores)\n",
    "        gt_scores = to_numpy(df_faceage['score'].tolist())\n",
    "        current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "        if current_tau < 0:\n",
    "            r_est_np = -r_est_np\n",
    "        crowdbt_acc = compute_acc(df_faceage, 1*r_est_np, device)\n",
    "        crowdbt_wacc = compute_weighted_acc(df_faceage, 1*r_est_np, device)\n",
    "        crowdbt_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "        CrowdBT_accs.append(crowdbt_acc)\n",
    "        CrowdBT_waccs.append(crowdbt_wacc)\n",
    "        CrowdBT_taus.append(crowdbt_tau)\n",
    "    except Exception as e:\n",
    "        print(f\"CrowdBT seed {seed} failed for N={N},K={K} with error {e}; appending zeros\")\n",
    "        CrowdBT_accs.append(0.0)\n",
    "        CrowdBT_waccs.append(0.0)\n",
    "        CrowdBT_taus.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1657bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrowdBT -- Accuracy: 0.7044227123260498 ± 0.0008876429468347528, Weighted Accuracy: 0.7640507102012635 ± 0.000879096424574269, Kendall's Tau: 0.38595374488838885 ± 0.001675885754137508\n"
     ]
    }
   ],
   "source": [
    "print(f\"CrowdBT -- Accuracy: {np.mean(CrowdBT_accs)} ± {np.std(CrowdBT_accs)}, Weighted Accuracy: {np.mean(CrowdBT_waccs)} ± {np.std(CrowdBT_waccs)}, Kendall's Tau: {np.mean(CrowdBT_taus)} ± {np.std(CrowdBT_taus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97ab32",
   "metadata": {},
   "source": [
    "### FactorBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3c665ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crowdkit.aggregation import NoisyBradleyTerry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da033e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df(df, column_name):\n",
    "    # Sort by a specific column (replace 'column_name' with your column)\n",
    "    df_sorted = df.sort_values(by=column_name, ascending=True)  # or ascending=False\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/passage_cleaned.csv\")\n",
    "df = df.rename(columns={'performer': 'worker'})\n",
    "\n",
    "agg_noisybt = NoisyBradleyTerry(n_iter=10).fit_predict(df)\n",
    "agg_noisybt_df = pd.DataFrame(list(agg_noisybt.items()), columns=['label', 'score'])\n",
    "agg_noisybt_df = sort_df(agg_noisybt_df, 'label')\n",
    "factorbt_scores = list(agg_noisybt_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45883e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# factorbt_test = FactorBT(data = PC_faceage, penalty = 0, classes = classes, device=device)\n",
    "# factorbt_scores,y,z = factorbt_test.alternate_optim(iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3cc711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(\"data/gt_df_passage.csv\")\n",
    "gt_df = sort_df(gt_df, 'label')\n",
    "gt_scores = to_numpy(gt_df['score'].tolist())\n",
    "r_est_np = to_numpy(factorbt_scores)\n",
    "\n",
    "current_tau = safe_kendalltau(r_est_np, gt_scores)\n",
    "if current_tau < 0:\n",
    "    r_est_np = -r_est_np\n",
    "factorbt_acc = compute_acc(gt_df, 1*r_est_np, device)\n",
    "factorbt_wacc = compute_weighted_acc(gt_df, 1*r_est_np, device)\n",
    "factorbt_tau = safe_kendalltau(r_est_np, gt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bd687c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactorBT -- Accuracy: 0.6973661780357361, Weighted Accuracy: 0.74295973777771, Kendall's Tau: 0.3726308644381563 \n"
     ]
    }
   ],
   "source": [
    "print(f\"FactorBT -- Accuracy: {factorbt_acc}, Weighted Accuracy: {factorbt_wacc}, Kendall's Tau: {factorbt_tau} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
